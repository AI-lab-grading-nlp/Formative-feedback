{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing huggingface_hub...\n",
      "\n",
      "Installing dependencies from Pipfile.lock (453c1b)...\n",
      "To activate this project's virtualenv, run pipenv shell.\n",
      "Alternatively, run a command inside the virtualenv with pipenv run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[    ] Installing..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[====] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[====] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[====] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[   =] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[====] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[    ] Installing huggingface_hub..\n",
      "[=   ] Installing huggingface_hub..\n",
      "[==  ] Installing huggingface_hub..\n",
      "[=== ] Installing huggingface_hub..\n",
      "[ ===] Installing huggingface_hub..\n",
      "[  ==] Installing huggingface_hub...\n",
      "Adding huggingface_hub to Pipfile's [packages]...\n",
      "\bInstallation Succeeded \n",
      "Pipfile.lock (62e467) out of date, updating to (453c1b)...\n",
      "Locking [dev-packages] dependencies...\n",
      "Locking [packages] dependencies...\n",
      "\n",
      "[    ] Locking...\n",
      "Building requirements...\n",
      "\n",
      "Resolving dependencies...\n",
      "\b\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..\n",
      "[  ==] Locking..\n",
      "[   =] Locking..\n",
      "[    ] Locking..\n",
      "[   =] Locking..\n",
      "[  ==] Locking..\n",
      "[ ===] Locking..\n",
      "[====] Locking..\n",
      "[=== ] Locking..\n",
      "[==  ] Locking..\n",
      "[=   ] Locking..\n",
      "[    ] Locking..\n",
      "[=   ] Locking..\n",
      "[==  ] Locking..\n",
      "[=== ] Locking..\n",
      "[ ===] Locking..Success! \n",
      "Updated Pipfile.lock (453c1b)!\n",
      "  \u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m\u001b[32m\u001b[1m=\u001b[0m 0/0 - 00:00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# requirements:\n",
    "! pipenv install huggingface_hub\n",
    "! git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c897c794dcb748e182d5c93057ac5a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "#enter your API key, you can make one for free on HF\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceApi\n",
    "\n",
    "inference = InferenceApi(\"bigscience/bloom\",token=HfFolder.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def infer(prompt,\n",
    "          max_length = 250,\n",
    "          top_k = 0,\n",
    "          num_beams = 0,\n",
    "          no_repeat_ngram_size = 2,\n",
    "          top_p = 0.9,\n",
    "          seed=42,\n",
    "          temperature=0.76,\n",
    "          greedy_decoding = False,\n",
    "          return_full_text = False):\n",
    "    \n",
    "\n",
    "    top_k = None if top_k == 0 else top_k\n",
    "    do_sample = False if num_beams > 0 else not greedy_decoding\n",
    "    num_beams = None if (greedy_decoding or num_beams == 0) else num_beams\n",
    "    no_repeat_ngram_size = None if num_beams is None else no_repeat_ngram_size\n",
    "    top_p = None if num_beams else top_p\n",
    "    early_stopping = None if num_beams is None else num_beams > 0\n",
    "\n",
    "    params = {\n",
    "        \"max_new_tokens\": max_length,\n",
    "        \"top_k\": top_k,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature,\n",
    "        \"do_sample\": do_sample,\n",
    "        \"seed\": seed,\n",
    "        \"early_stopping\":early_stopping,\n",
    "        \"no_repeat_ngram_size\":no_repeat_ngram_size,\n",
    "        \"num_beams\":num_beams,\n",
    "        \"return_full_text\":return_full_text\n",
    "    }\n",
    "    \n",
    "    s = time.time()\n",
    "    response = inference(prompt, params=params)\n",
    "    #print(response)\n",
    "    proc_time = time.time()-s\n",
    "    #print(f\"Processing time was {proc_time} seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''The following is a grading rubric for assessing a student's skills at model selection:\n",
    "\n",
    "1 - Not enough information is present in the work to determine whether there is an understanding of concepts or mastery of skills. The work is fragmentary or contains significant omissions. Or, there are too many issues to justify correcting each one.\n",
    "2 - The work addresses some but not all requirements of the assignment. Partial understanding of concepts or mastery of skills is evident but significant gaps remain. It needs further work, more review, or much improved explanations.\n",
    "3 - The work addresses all requirements of the assignment. Mastery of concepts and skills is evident through correct work and clear, audience-appropriate explanations. Some revision or expansion is needed but there are no significant gaps or errors.\n",
    "4 - Everything in 3 applies. No revision or expansion is needed to improve the work or clarity of the explanations. The only errors that remain are trivial and easily fixable. The work is good enough to be used as an exemplar in class. \n",
    "\n",
    "\n",
    "\n",
    "Question:\n",
    "What grade would you give the following prompt from a student on the basis of the grading rubric above on the scale of 0 to 4.\n",
    "\n",
    "Prompt: Following the frequentist model selection recipe, we need to first describe the null model distribution. \n",
    "In this case, since we’re trying to find whether there is enough evidence to support Sho’s and Haruna’s individual probabilities of finding errors \n",
    "being different i.e. Is Haruna actually better at finding typos or was this within the realm of possibility. The null distribution in this case is \n",
    "something that we calculated in the previous part where the distribution of X1 given that X1 + X2 = t. Since we know the total number of typos both \n",
    "find is 613, the only random variable left is the total number of typos which we know can be made as a binomial distribution with n = 100,000 and \n",
    "probability per typo as 1/300 . In this case, our test statistic is getting a value as extreme as 299 for Sho given that the total number of typos is 613. \n",
    "For the simulation thus, I looked towards first generating a number of variables from the typo’s binomial distribution and then over all those, \n",
    "calculated the p-values of getting the value to be as extreme as 299 and then averaged those values to get the general p-value of being as extreme \n",
    "as this test statistic.\n",
    "Furthermore, for the purpose of this experiment, I looked at the standard significance value as being 0.05 to reject the null.\n",
    "\n",
    "*image of the simulation that the student used to calculate the p-value*\n",
    "\n",
    "Since the average p-value (0.03032509131636617) is less than 0.05, this tells us that the null\n",
    "hypothesis which is both having the same probability to find typos is not true. Thus, Haruna is\n",
    "better at finding typos\n",
    "\n",
    "Answer:\n",
    "'''\n",
    "resp = infer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a grading rubric for assessing a student's skills at model selection:\n",
      "\n",
      "1 - Not enough information is present in the work to determine whether there is an understanding of concepts or mastery of skills. The work is fragmentary or contains significant omissions. Or, there are too many issues to justify correcting each one.\n",
      "2 - The work addresses some but not all requirements of the assignment. Partial understanding of concepts or mastery of skills is evident but significant gaps remain. It needs further work, more review, or much improved explanations.\n",
      "3 - The work addresses all requirements of the assignment. Mastery of concepts and skills is evident through correct work and clear, audience-appropriate explanations. Some revision or expansion is needed but there are no significant gaps or errors.\n",
      "4 - Everything in 3 applies. No revision or expansion is needed to improve the work or clarity of the explanations. The only errors that remain are trivial and easily fixable. The work is good enough to be used as an exemplar in class. \n",
      "\n",
      "\n",
      "\n",
      "Question:\n",
      "What grade would you give the following prompt from a student on the basis of the grading rubric above on the scale of 0 to 4.\n",
      "\n",
      "Prompt: Following the frequentist model selection recipe, we need to first describe the null model distribution. \n",
      "In this case, since we’re trying to find whether there is enough evidence to support Sho’s and Haruna’s individual probabilities of finding errors \n",
      "being different i.e. Is Haruna actually better at finding typos or was this within the realm of possibility. The null distribution in this case is \n",
      "something that we calculated in the previous part where the distribution of X1 given that X1 + X2 = t. Since we know the total number of typos both \n",
      "find is 613, the only random variable left is the total number of typos which we know can be made as a binomial distribution with n = 100,000 and \n",
      "probability per typo as 1/300. In this case, our test statistic is getting a value as extreme as 299 for Sho given that the total number of typos is 613. \n",
      "For the simulation thus, I looked towards first generating a number of variables from the typo’s binomial distribution and then over all those, \n",
      "calculated the p-values of getting the value to be as extreme as 299 and then averaged those values to get the general p-value of being as extreme \n",
      "as this test statistic.\n",
      "Furthermore, for the purpose of this experiment, I looked at the standard significance value as being 0.05 to reject the null.\n",
      "\n",
      "*image of the simulation that the student used to calculate the p-value*\n",
      "\n",
      "Since the average p-value (0.03032509131636617) is less than 0.05, this tells us that the null\n",
      "hypothesis which is both having the same probability to find typos is not true. Thus, Haruna is\n",
      "better at finding typos\n",
      "\n",
      "Answer:\n",
      "I would give a score of 2.\n",
      "The student has correctly identified the null distribution and test statistic, however, the student is not doing the simulation correctly. \n",
      "The student is using the binomial distribution to generate a number of variables from the typo’s binomial distribution and then over all those, calculating the p-values of getting the value to be as extreme as 299 and then averaging those values to get the general p-value of being as extreme as this test statistic.\n",
      "The student is not actually doing the simulation correctly. The student is calculating the p-value of being as extreme as the test statistic 299 without generating a number of variables from the typo’s binomial distribution. Instead, the student is generating a number of variables from the typo’s binomial distribution and then calculating the p-value of getting the value to be as extreme as 299.\n",
      "Furthermore, the student is not using the correct significance level. The student is using the standard significance value as being 0.05 to reject the null. The student should be using the significance level of the simulation as being 0.05 to reject the null.\n",
      "Instead, the student should be doing the simulation as follows:\n",
      "\n",
      "Generate a number of variables from the typo’s binomial distribution and calculate the p-value of getting the value to be as extreme as\n"
     ]
    }
   ],
   "source": [
    "print(resp[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
